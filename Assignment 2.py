# -*- coding: utf-8 -*-
"""Assignment2_Question1 (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fHC0S0LaismWHjrmKD9qnpGP4YCxEK9u
"""

from gurobipy import GRB
import gurobipy as gb
import pandas as pd
import numpy as np
import autograd as ag

# Create the optimization model
model = gb.Model("Question 1a): TechEssentials Certain Product Line")

# Read costs from CSV files
price_response_df = pd.read_csv(r"C:\Users\gabri\Downloads\price_response.csv")

price_response_df.head(10)

# Extract the "Intercept", "Capacity", and "Sensitivity" column
intercept_values = price_response_df['Intercept'].values.reshape(3, -1)
product_capacity = price_response_df['Capacity'].values.reshape(3, -1)
slope = price_response_df['Sensitivity'].values.reshape(3, -1)

intercept_values

product_capacity

slope

"""# Part a)"""

from scipy.optimize import minimize

# Objective function (negated for maximization)
def objective(p):
    p1, p2 = p
    return -1 * (p1 * (intercept_values[0,0] + slope[0,0] * p1) + p2 * (intercept_values[0,1] + slope[0,1] * p2))

# Constraint functions
def constraint1(p):
    return p[1] - p[0]

def constraint2(p):
    return intercept_values[0,0] + slope[0,0] * p[0]

def constraint3(p):
    return intercept_values[0,1] + slope[0,1] * p[1]

# KKT conditions using only constraint1
def kkt_conditions(p, lagrange_multipliers):
    grad_objective = [-(intercept_values[0,0] + 2 * slope[0,0] * p[0]), -(intercept_values[0,1] + 2 * slope[0,1] * p[1])]
    grad_constraint1 = [-1, 1]

    # Stationarity condition
    stationarity = [grad_objective[i] + lagrange_multipliers[0] * grad_constraint1[i] for i in range(len(p))]

    # Complementary slackness conditions
    complementary_slackness = lagrange_multipliers[0] * constraint1(p)

    # Feasibility conditions
    feasibility = constraint1(p)

    return stationarity + [complementary_slackness] + [feasibility]

# Initial guess for Lagrange multipliers
initial_lagrange_multipliers = [1.0]

# Bounds for Lagrange multipliers
bounds_lagrange_multipliers = [(0, None)] * len(initial_lagrange_multipliers)

# Initial guess
initial_guess = [0, 0]

# Bounds for variables
bounds = [(0, None), (0, None)]  # P1 and P2 are non-negative

# Solve using minimize with original objective and constraints
result = minimize(objective, initial_guess, bounds=bounds, constraints=[{'type': 'ineq', 'fun': constraint1},
                                                                       {'type': 'ineq', 'fun': constraint2},
                                                                       {'type': 'ineq', 'fun': constraint3}])

# Extract solution
p_solution = result.x
maximized_profit = -1 * result.fun  # Convert back to positive for interpretation

# Now that p_solution is defined, you can use it in the minimize function for Lagrange multipliers

result = minimize(lambda lagrange_multipliers: sum([val**2 for val in kkt_conditions(p_solution, lagrange_multipliers)]),
                  initial_lagrange_multipliers,
                  bounds=bounds_lagrange_multipliers)

# Extract Lagrange multipliers solution
lagrange_multipliers_solution = result.x

print("Optimal values:")
print("P1:", p_solution[0])
print("P2:", p_solution[1])
print("Maximized Revenue:", maximized_profit)
print("Lagrange Multipliers:", lagrange_multipliers_solution)

"""# Part b)"""

# Objective function
def objective_function(p1, p2):
    return p1 * (intercept_values[0,0] + slope[0,0] * p1) + p2 * (intercept_values[0,1] + slope[0,1] * p2)

# Projected Gradient Descent with Gurobi
def projected_gradient_descent_with_gurobi(learning_rate, threshold):
    # Initialize Gurobi model
    model = gb.Model("projected_gradient_descent")

    # Decision variables
    p1 = model.addVar(lb=0, vtype=GRB.CONTINUOUS, name="p1")
    p2 = model.addVar(lb=0, vtype=GRB.CONTINUOUS, name="p2")

    # Objective
    obj = p1 * (intercept_values[0,0] + slope[0,0] * p1) + p2 * (intercept_values[0,1] + slope[0,1] * p2)
    model.setObjective(obj, GRB.MAXIMIZE)

    # Optimization loop
    prev_obj = float('inf')
    i = 0

    while True:
        # Price Constraint
        model.addConstr(p1 <= p2, f"Price Constraint {i}")

        model.addConstr(intercept_values[0,0] + slope[0,0]*p1 >= 0, "Demand Definition Product Line 1 Basic")
        model.addConstr(intercept_values[0,1] + slope[0,1]*p2 >= 0, "Demand Definition Product Line 1 Advance")

        # Optimize model
        model.optimize()

        # Get current solution
        current_p1 = p1.X
        current_p2 = p2.X

        # Compute objective function
        current_obj = objective_function(current_p1, current_p2)

        # Check convergence
        if (current_obj - prev_obj) < threshold:
            break

        prev_obj = current_obj

        # Compute gradient
        df_dx = intercept_values[0,0] + 2 * slope[0,0] * current_p1
        df_dy = intercept_values[0,1] + 2 * slope[0,1] * current_p2

        # Update parameters
        current_p1 -= learning_rate * df_dx
        current_p2 -= learning_rate * df_dy

        # Set new starting point
        p1.Start = current_p1
        p2.Start = current_p2

        # Increment iteration counter
        i += 1

    return current_p1, current_p2

# Hyperparameters
learning_rate = 0.001
threshold = 1e-6

# Run projected gradient descent with Gurobi
final_x, final_y = projected_gradient_descent_with_gurobi(learning_rate, threshold)
print(f"Final solution: x = {final_x}, y = {final_y}, Objective = {round(objective_function(final_x, final_y),10)}")

"""# Part c)"""

# Create the optimization model
part_c_model = gb.Model("Question 1c): TechEssentials Certain Product Line")

p = part_c_model.addVars(3,3, lb=0, vtype=GRB.CONTINUOUS, name="Price")

#Objective Function
part_c_model.setObjective(gb.quicksum(p[i,n]*(intercept_values[i,n] + slope[i,n]*p[i,n]) for i in range(3) for n in range(3)), GRB.MAXIMIZE)

for i in range(3):
    for n in range(3):
        part_c_model.addConstr((intercept_values[i,n] + slope[i,n]*p[i,n]) >= 0, "Demand Lower Bound")

# Price Constraint
for n in range(2):
    part_c_model.addConstr(p[0, n] <= p[0, n + 1], f"Price Constraint {i}")
    part_c_model.addConstr(p[1, n] <= p[1, n + 1], f"Price Constraint {i}")
    part_c_model.addConstr(p[2, n] <= p[2, n + 1], f"Price Constraint {i}")

for i in range(3):
    for n in range(3):
        part_c_model.addConstr((intercept_values[i,n] + slope[i,n]*p[i,n]) <= product_capacity[i,n], "Max Demand")

# Solve our model
part_c_model.optimize()

# Value of the objective function
print("Revenue: ", round(part_c_model.objVal,2))

# Print the decision variables
print(part_c_model.printAttr('X'))

"""# Part d)"""

# Create the optimization model
part_d_model = gb.Model("Question 1d): TechEssentials Certain Product Line")

p = part_d_model.addVars(3,3, lb=0, vtype=GRB.CONTINUOUS, name="Price")

#Objective Function
part_d_model.setObjective(gb.quicksum(p[i,n]*(intercept_values[i][n] + slope[i][n]*p[i,n]) for i in range(3) for n in range(3)), GRB.MAXIMIZE)

for i in range(3):
    for n in range(3):
        part_d_model.addConstr((intercept_values[i][n] + slope[i][n]*p[i,n]) >= 0, "Demand Lower Bound")

# Price Constraint
for n in range(2):
    part_d_model.addConstr(p[0, n] <= p[0, n + 1], f"Price Constraint {i}")
    part_d_model.addConstr(p[1, n] <= p[1, n + 1], f"Price Constraint {i}")
    part_d_model.addConstr(p[2, n] <= p[2, n + 1], f"Price Constraint {i}")

for n in range(2):
    part_d_model.addConstr(p[n, 0] <= p[n + 1, 0], f"Price Constraint {i}")
    part_d_model.addConstr(p[n, 1] <= p[n + 1, 1], f"Price Constraint {i}")
    part_d_model.addConstr(p[n, 2] <= p[n + 1, 2], f"Price Constraint {i}")

#part_d_model.addConstr(p[0, 1] <= p[1, 0], f"Price Constraint Additional 1")
#part_d_model.addConstr(p[0, 2] <= p[1, 0], f"Price Constraint Additional 2")
#part_d_model.addConstr(p[1, 1] <= p[2, 0], f"Price Constraint Additional 3")
#part_d_model.addConstr(p[1, 2] <= p[2, 0], f"Price Constraint Additional 4")

for i in range(3):
    for n in range(3):
        part_d_model.addConstr((intercept_values[i,n] + slope[i,n]*p[i,n]) <= product_capacity[i,n], "Max Demand")

# Solve our model
part_d_model.optimize()

# Value of the objective function
print("Revenue: ", round(part_d_model.objVal,2))

# Print the decision variables
print(part_d_model.printAttr('X'))

# Extract values from the tupledict
values = [v for v in part_d_model.getAttr('x', p).values()]

# Reshape the values
price_values = np.array(values).reshape(3, -1)

price_values

demand = [[intercept_values[i][n] + slope[i][n] * price_values[i][n] for n in range(3)] for i in range(3)]
demand


#Question 2


# -*- coding: utf-8 -*-
"""Assignment2_Question2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eMRf7F6l2ZBHk5T9HvUlgov9vaqysALV
"""

from gurobipy import GRB
import gurobipy as gb
import pandas as pd
import numpy as np

# Create the optimization model
question_2_model = gb.Model("Question 2: Canadian Womens National Team Selection")

player_value_df = pd.read_csv(r"C:\Users\gabri\Downloads\BasketballPlayers.csv")

player_value_df

x = question_2_model.addVars(150, lb=0, vtype=GRB.BINARY, name="Players")

final_seven_columns = player_value_df.iloc[:, -7:]
final_seven_columns

average_per_row = final_seven_columns.mean(axis=1)
total_per_row = final_seven_columns.sum(axis=1)

print(average_per_row)

print(total_per_row)

objective_function = gb.quicksum(total_per_row[i]*x[i] for i in range(150))
question_2_model.setObjective(objective_function, GRB.MAXIMIZE)

# Add the constraints
question_2_model.addConstr(gb.quicksum(x[i] for i in range(150)) <= 21, "Team Limit Constraint")

player_positions = player_value_df['Position'].values
player_positions

guard_indices = []
for pos in player_positions:
    if pos in ['G', 'G/F']:
        guard_indices.append(1)
    else:
        guard_indices.append(0)

guard_indices

question_2_model.addConstr((gb.quicksum(guard_indices[i]*x[i] for i in range(150)) >= (0.3*(gb.quicksum(x[i] for i in range(150))))), "Guard Constraint")

other_indices = []
for pos in player_positions:
    if pos in ['F', 'C', 'F/C']:
        other_indices.append(1)
    else:
        other_indices.append(0)

other_indices

question_2_model.addConstr((gb.quicksum(other_indices[i]*x[i] for i in range(150)) >= (0.4*(gb.quicksum(x[i] for i in range(150))))), "Other Position Constraint")

question_2_model.addConstr(gb.quicksum(average_per_row[i]*x[i] for i in range(150)) >= 2.05*(gb.quicksum(x[i] for i in range(150))), "Average Value Constraint")

for i in range(19,24):
    for j in range(71,78):
        question_2_model.addConstr(x[i] <= 1 - (x[j]), "First Logical Constraint Expression")

for i in range(104,114):
    question_2_model.addConstr(x[i] <= x[44] + x[45] + x[46] + x[47] + x[48], "First Part of Second Logical Constraint Expression")
    question_2_model.addConstr(x[i] <= x[64] + x[65] + x[66] + x[67] + x[68], "Second Part of Second Logical Constraint Expression")

question_2_model.addConstr(gb.quicksum(x[i] for i in range (10)) >= 1, "Logical Constraint 1")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(10, 20)) >= 1, "Logical Constraint 2")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(20, 30)) >= 1, "Logical Constraint 3")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(30, 40)) >= 1, "Logical Constraint 4")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(40, 50)) >= 1, "Logical Constraint 5")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(50, 60)) >= 1, "Logical Constraint 6")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(60, 70)) >= 1, "Logical Constraint 7")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(70, 80)) >= 1, "Logical Constraint 8")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(80, 90)) >= 1, "Logical Constraint 9")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(90, 100)) >= 1, "Logical Constraint 10")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(100, 110)) >= 1, "Logical Constraint 11")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(110, 120)) >= 1, "Logical Constraint 12")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(120, 130)) >= 1, "Logical Constraint 13")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(130, 140)) >= 1, "Logical Constraint 14")
question_2_model.addConstr(gb.quicksum(x[i] for i in range(140, 150)) >= 1, "Logical Constraint 15")

# Optimally solve the problem
question_2_model.optimize()

# Value of the objective function
print("Value to the Team: ", question_2_model.objVal)

# Print the decision variables
print(question_2_model.printAttr('X'))

players_picked = question_2_model.getAttr('X', x)
players_picked

total_players_picked = int(sum(players_picked[i] for i in players_picked))
print("Total Players Picked:", total_players_picked)

guard_invitations = gb.quicksum(guard_indices[i] * players_picked[i] for i in range (150))
print(guard_invitations)
percent_of_guard_selections = (guard_invitations / total_players_picked) * 100
print(percent_of_guard_selections)

other_invitations = gb.quicksum(other_indices[i] * players_picked[i] for i in range (150))
print(other_invitations)
percent_of_other_selections = (other_invitations / total_players_picked) * 100
print(percent_of_other_selections)